import os
import logging
import numpy as np
import cv2
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import joblib
from PIL import Image

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 1. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Dropout(0.3)
        )
        self.fc_layers = nn.Sequential(
            nn.Linear(64 * 28 * 28, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 2), # 2 –∫–ª–∞—Å—Å–∞: Real (0) –∏ AI (1)
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layers(x)
        return x


# 2. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–π—Å—Ç–≤

def extract_features(image_array):
    try:
        if len(image_array.shape) == 2:
            image_array = cv2.cvtColor(image_array, cv2.COLOR_GRAY2RGB)

        features = {}
        # –Ø—Ä–∫–æ—Å—Ç—å –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç
        gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)
        features['brightness'] = np.mean(gray)
        features['contrast'] = np.std(gray)

        # –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã (—Ä–µ–∑–∫–æ—Å—Ç—å)
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient = np.sqrt(sobelx**2 + sobely**2)
        features['gradient_mean'] = np.mean(gradient)

        # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
        hist = cv2.calcHist([gray], [0], None, [16], [0, 256])
        hist = hist.flatten() / (hist.sum() + 1e-6)

        # –°–æ–±–∏—Ä–∞–µ–º –≤–µ–∫—Ç–æ—Ä
        feature_vector = [features['brightness'], features['contrast'], features['gradient_mean']]
        feature_vector.extend(hist)

        return np.array(feature_vector)
    except Exception as e:
        logger.error(f"Error extracting features: {e}")
        return np.zeros(19) # 3 scalar + 16 hist bins

# 3. –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è
def train_and_save():
    os.makedirs('models', exist_ok=True)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {device}")

    # --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
    IMG_SIZE = (224, 224)
    BATCH_SIZE = 32
    EPOCHS = 15
    DATASET_PATH = 'dataset' # –û–∂–∏–¥–∞–µ—Ç—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: dataset/train/real –∏ dataset/train/ai - —Ç—É–¥–∞ –∑–∞–∫–∏–¥—ã–≤–∞–µ–º –ü–†–ò–ú–ï–†–´

    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    transform = transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    cnn_model = SimpleCNN().to(device)
    rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
    scaler = StandardScaler()

    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö ---
    has_data = os.path.exists(DATASET_PATH) and os.path.exists(os.path.join(DATASET_PATH, 'train'))

    if has_data:
        print("üìÇ –ù–∞–π–¥–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç. –ù–∞—á–∏–Ω–∞—é —Ä–µ–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ...")

        # 1. –û–±—É—á–µ–Ω–∏–µ CNN
        train_dataset = ImageFolder(root=os.path.join(DATASET_PATH, 'train'), transform=transform)
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)

        cnn_model.train()
        for epoch in range(EPOCHS):
            running_loss = 0.0
            for images, labels in train_loader:
                images, labels = images.to(device), labels.to(device)
                optimizer.zero_grad()
                outputs = cnn_model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                running_loss += loss.item()
            print(f"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader):.4f}")

        print("üìä –û–±—É—á–µ–Ω–∏–µ Random Forest –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö...")
        X_features = []
        y_labels = []

        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Ç–µ–º –∂–µ –∫–∞—Ä—Ç–∏–Ω–∫–∞–º –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ opencv
        for class_name in ['real', 'ai']:
            class_dir = os.path.join(DATASET_PATH, 'train', class_name)
            #label = 0 if class_name == 'real' else 1
            label = 1 if class_name == 'real' else 0
            if not os.path.exists(class_dir): continue

            for img_name in os.listdir(class_dir):
                try:
                    img_type = "__ AI __ "
                    if label == 1: img_type = "__REAL__ "
                    img_path = os.path.join(class_dir, img_name)
                    logger.info(f"Training on {img_type} image: {img_path}")
                    img = cv2.imread(img_path)
                    if img is None: continue
                    feats = extract_features(img)
                    X_features.append(feats)
                    y_labels.append(label)
                except: pass

        if X_features:
            X_features = np.array(X_features)
            X_features = scaler.fit_transform(X_features)
            rf_classifier.fit(X_features, y_labels)

    else:
        print("‚ö†Ô∏è –î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–ª–æ–∂–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã!")

    # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ---
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
    torch.save(cnn_model.state_dict(), 'models/cnn_model.pth')
    joblib.dump(rf_classifier, 'models/classifier.joblib')
    joblib.dump(scaler, 'models/scaler.joblib')
    print("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É models/!")

if __name__ == "__main__":
    train_and_save()
